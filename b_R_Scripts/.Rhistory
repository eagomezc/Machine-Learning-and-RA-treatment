setwd("C:/Users/hhy270/Google Drive/PhD/18 months report/Shiny Machine Learning LM/MachineLearningLM/example")
#--------------------------------------------- ROC curves ML LIPIDOMIC DATA -------------------------------------------#
# This script compiles the ROC curve analysis for different ML methodologies: random forest, SVM, Elastic Net and
# bayesian models.
#---> LIBRARY LOAD:
if (!require('randomForest')) install.packages('randomForest'); library('randomForest')
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
if (!require('gridExtra')) install.packages('gridExtra'); library('gridExtra')
if (!require('snowfall')) install.packages('snowfall')
if (!require('neldermead')) install.packages('neldermead')
if (!require('optimbase')) install.packages('optimbase')
if (!require('classyfire')) install.packages("../classyfire_0.1-2.tar.gz",
repos = NULL,
type = "source"); library('classyfire')
if (!require('glmnet')) install.packages('glmnet'); library('glmnet')
if (!require('caret')) install.packages('caret'); library('caret')
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
if (!require('arm')) install.packages('dplyr'); library('arm')
if (!require('pROC')) install.packages('pROC'); library('pROC')
set.seed(415) # To get same results even with the random part.
options(digits = 3) # To get only part of the decimals.
#---> INPUT FILE:
# Upload testing file:
val_profile <- read.table(
file = "../../input/2_ROC_curves/2_randomForest_(RF_models)_data_validation.tsv",
header = TRUE,
row.names = 1, # Specify that the first column is row names.
sep = "\t",
stringsAsFactors = FALSE)
# Separates the profiles data by lipid mediators types:
substrates <- unique(unname(unlist(val_profile[1, -1])))
# Creates data frames for each subset:
dataframes_list <- list("ALL LM" = val_profile[, -1])
for (e in 1:length(substrates)) {
substrate <- val_profile[ ,val_profile[1, ]== substrates[[e]]]
assign(substrates[[e]], substrate)
}
if (exists('DHA') == TRUE) {dataframes_list[["DHA"]] <- DHA}
if (exists('n3DPA') == TRUE) {dataframes_list[["n3DPA"]] <- n3DPA}
if (exists('EPA') == TRUE) {dataframes_list[["EPA"]] <- EPA}
if (exists('AA') == TRUE) {dataframes_list[["AA"]] <- AA}
# Upload models with a loop:
models <- c( "rf", "svm", "bayesian", "net")
metabolomes <- c("ALL LM", "DHA", "n3DPA", "EPA", "AA")
auc_final_table <- data.frame(machine_learning = "del",
groups = "del",
auc = 1,
sensitivity = 1,
specificity = 1,
TP = 1,
FP = 1,
TN = 1,
FN = 1,
stringsAsFactors = FALSE)
for (i in 1:length(models)) {
for (j in 1:length(metabolomes)) {
# Open the model:
model <- readRDS(file = paste("../../input/2_ROC_curves/", models[[i]], "_", metabolomes[[j]], ".R", sep = ""),
refhook = NULL)
# Get the table:
val_file <- dataframes_list[[j]]
# Save all the values as numeric:
lm_profile_number <- sapply(val_file[-1, ], function(x) as.numeric(x))
row.names(lm_profile_number) <- row.names(val_file[-1, ])
# Scale the data because is better when you are running Machine Learning models:
lm_profiles_scale <- as.data.frame(scale(lm_profile_number, center = FALSE, scale = TRUE))
# If all the values from one column are the same, the scalation will give you NA. For those cases, to avoid errors,
# replace the NA for zeros.
lm_profiles_scale[is.na(lm_profiles_scale)] <- 0
# Make sure that column names do not represent a problem to randomForest making them a valid name to R.
names(lm_profiles_scale) <- make.names(names(lm_profiles_scale))
#-----> ROC curves random forest:
if (models[[i]] == "rf") {
pred_rf_lm_profiles_p <- as.data.frame(predict(model, lm_profiles_scale, type = "prob"))
rf_roc_value = roc(val_profile[-1, ]$groups, pred_rf_lm_profiles_p$Non_Responder)
# Confusion table:
pred_rf_lm_profiles <- as.data.frame(predict(model, lm_profiles_scale))
names(pred_rf_lm_profiles) <- c("prediction")
confusion_val <- confusionMatrix(factor(pred_rf_lm_profiles$prediction, levels = c("Responder", "Non_Responder")),
factor(val_profile[-1, ]$groups, levels = c("Responder", "Non_Responder")))
table_parameters <- as.data.frame(confusion_val$byClass)
auc_table <- data.frame(machine_learning = models[[i]],
groups = metabolomes[[j]],
auc = round(rf_roc_value$auc, digits = 2),
sensitivity = round(table_parameters[1,1], digits = 2),
specificity = round(table_parameters[2,1], digits = 2),
TP = round(table_parameters[1,1]*100, digits = 0),
FP = 100 - round(table_parameters[2,1]*100, digits = 0),
TN = round(table_parameters[2,1]*100, digits = 0),
FN = 100 - round(table_parameters[1,1]*100, digits = 0),
stringsAsFactors = FALSE)
auc_final_table <- rbind(auc_final_table, auc_table)
}
#-----> ROC curves SVM:
if (models[[i]] == "svm") {
prediction_validation <- cfPredict(model, lm_profiles_scale)
names(prediction_validation) <- c("prediction", "Coef Score")
# For ROC curves we need the likehood of each sample to belong to one group of another. We add two new columns for
# that purpose:
prediction_validation$Responder[prediction_validation$prediction == "Responder"] <-
prediction_validation$`Coef Score`[prediction_validation$prediction == "Responder"]/100
prediction_validation$Responder[prediction_validation$prediction == "Non_Responder"] <-
1 - (prediction_validation$`Coef Score`[prediction_validation$prediction == "Non_Responder"]/100)
prediction_validation$Non_Responder <- 1 - prediction_validation$Responder
# Confusion Matrix for the validation:
confusion_val <- confusionMatrix(factor(prediction_validation$prediction, levels = c("Responder", "Non_Responder")),
factor(val_profile[-1, ]$groups, levels = c("Responder", "Non_Responder")))
table_parameters <- as.data.frame(confusion_val$byClass)
# In order to further evaluate the predictivenss of this approach we next the ROC curves (AUC):
svm_roc_value = roc(val_profile[-1, ]$groups, prediction_validation$Non_Responder)
auc_table <- data.frame(machine_learning = models[[i]],
groups = metabolomes[[j]],
auc = round(svm_roc_value$auc, digits = 2),
sensitivity = round(table_parameters[1,1], digits = 2),
specificity = round(table_parameters[2,1], digits = 2),
TP = round(table_parameters[1,1]*100, digits = 0),
FP = 100 - round(table_parameters[2,1]*100, digits = 0),
TN = round(table_parameters[2,1]*100, digits = 0),
FN = 100 - round(table_parameters[1,1]*100, digits = 0),
stringsAsFactors = FALSE)
auc_final_table <- rbind(auc_final_table, auc_table)
}
#-----> ROC curves Elastic Net and Bayesian:
if (models[[i]] == "bayesian" | models[[i]] == "net") {
lm_profiles_scale <- data.matrix(lm_profiles_scale)
prediction_validation <- predict.train(model, newdata = lm_profiles_scale, type = "prob")
rownames(prediction_validation) <- rownames(lm_profiles_scale)
caret_roc_value = roc(val_profile[-1, ]$groups, prediction_validation$Non_Responder)
# Confusion validation:
prediction_validation <- as.data.frame(predict.train(model, newdata = lm_profiles_scale))
names(prediction_validation) <- c("prediction")
confusion_val <- confusionMatrix(factor(prediction_validation$prediction, levels = c("Responder", "Non_Responder")),
factor(val_profile[-1, ]$groups, levels = c("Responder", "Non_Responder")))
table_parameters <- as.data.frame(confusion_val$byClass)
auc_table <- data.frame(machine_learning = models[[i]],
groups = metabolomes[[j]],
auc = round(caret_roc_value$auc, digits = 2),
sensitivity = round(table_parameters[1,1], digits = 2),
specificity = round(table_parameters[2,1], digits = 2),
TP = round(table_parameters[1,1]*100, digits = 0),
FP = 100 - round(table_parameters[2,1]*100, digits = 0),
TN = round(table_parameters[2,1]*100, digits = 0),
FN = 100 - round(table_parameters[1,1]*100, digits = 0),
stringsAsFactors = FALSE)
auc_final_table <- rbind(auc_final_table, auc_table)
}
}
}
val_clin_score <- read.table(
file = "../../input/2_ROC_curves/validation_clinical_score no pa or das.tsv",
header = TRUE,
row.names = 1, # Specify that the first column is row names.
sep = "\t",
stringsAsFactors = FALSE)
View(val_clin_score)
View(val_clin_score)
validation_clinical <- read.table(
file = "../../input/2_ROC_curves/validation_clinical_score no pa or das.tsv",
header = TRUE,
row.names = 1, # Specify that the first column is row names.
sep = "\t",
stringsAsFactors = FALSE)
names(validation_clinical) <- make.names(names(validation_clinical))
validation_clinical$responses <- as.factor(c(rep("responder", 36), rep("non_responder", 8)))
validation_clinical <- rfImpute(responses ~ ., data = validation_clinical, iter = 6, ntree = 10000)
clinical_scores_impute <- sapply(validation_clinical, function(x) as.character(x))
clinical_scores_impute <- sapply(validation_clinical, function(x) as.numeric(x))
clinical_score_no_pt <- readRDS(file = "../../input/2_ROC_curves/RF_clinical_score_no_pt_noDAS.R",
refhook = NULL)
View(clinical_scores_impute)
validation_clinical <- read.table(
file = "../../input/2_ROC_curves/validation_clinical_score no pa or das.tsv",
header = TRUE,
row.names = 1, # Specify that the first column is row names.
sep = "\t",
stringsAsFactors = FALSE)
names(validation_clinical) <- make.names(names(validation_clinical))
validation_clinical$responses <- as.factor(c(rep("responder", 36), rep("non_responder", 8)))
validation_clinical <- rfImpute(responses ~ ., data = validation_clinical, iter = 6, ntree = 10000)
clinical_scores_impute[, -1] <- sapply(validation_clinical[, -1], function(x) as.character(x))
clinical_scores_impute[, -1] <- sapply(validation_clinical[, -1], function(x) as.numeric(x))
View(clinical_scores_impute)
validation_clinical <- read.table(
file = "../../input/2_ROC_curves/validation_clinical_score no pa or das.tsv",
header = TRUE,
row.names = 1, # Specify that the first column is row names.
sep = "\t",
stringsAsFactors = FALSE)
names(validation_clinical) <- make.names(names(validation_clinical))
validation_clinical$responses <- as.factor(c(rep("responder", 36), rep("non_responder", 8)))
validation_clinical <- rfImpute(responses ~ ., data = validation_clinical, iter = 6, ntree = 10000)
View(validation_clinical)
clinical_scores_impute <- sapply(validation_clinical[, -1], function(x) as.character(x))
clinical_scores_impute <- sapply(validation_clinical[, -1], function(x) as.numeric(x))
View(clinical_scores_impute)
clinical_score_no_pt <- readRDS(file = "../../input/2_ROC_curves/RF_clinical_score_no_pt_noDAS.R",
refhook = NULL)
pred_rf_lm_profiles_p <- as.data.frame(predict(clinical_score_no_pt, clinical_scores_impute[, -1], type = "prob"))
pred_rf_lm_profiles_p <- as.data.frame(predict(clinical_score_no_pt, clinical_scores_impute, type = "prob"))
View(pred_rf_lm_profiles_p)
validation_clinical <- read.table(
file = "../../input/2_ROC_curves/validation_clinical_score no pa or das.tsv",
header = TRUE,
row.names = 1, # Specify that the first column is row names.
sep = "\t",
stringsAsFactors = FALSE)
names(validation_clinical) <- make.names(names(validation_clinical))
validation_clinical$responses <- as.factor(c(rep("Responder", 36), rep("Non_Responder", 8)))
validation_clinical <- rfImpute(responses ~ ., data = validation_clinical, iter = 6, ntree = 10000)
clinical_scores_impute <- sapply(validation_clinical[, -1], function(x) as.character(x))
clinical_scores_impute <- sapply(validation_clinical[, -1], function(x) as.numeric(x))
clinical_score_no_pt <- readRDS(file = "../../input/2_ROC_curves/RF_clinical_score_no_pt_noDAS.R",
refhook = NULL)
pred_rf_lm_profiles_p <- as.data.frame(predict(clinical_score_no_pt, clinical_scores_impute, type = "prob"))
rf_roc_value = roc(validation_clinical$responses, pred_rf_lm_profiles_p$Non_Responder)
validation_clinical$responses
View(pred_rf_lm_profiles_p)
validation_clinical <- read.table(
file = "../../input/2_ROC_curves/validation_clinical_score no pa or das.tsv",
header = TRUE,
row.names = 1, # Specify that the first column is row names.
sep = "\t",
stringsAsFactors = FALSE)
names(validation_clinical) <- make.names(names(validation_clinical))
validation_clinical$responses <- as.factor(c(rep("Responder", 36), rep("Non_Responder", 8)))
View(validation_clinical)
validation_clinical <- rfImpute(responses ~ ., data = validation_clinical, iter = 6, ntree = 10000)
View(validation_clinical)
clinical_scores_impute <- sapply(validation_clinical[, -1], function(x) as.character(x))
clinical_scores_impute <- sapply(validation_clinical[, -1], function(x) as.numeric(x))
clinical_score_no_pt <- readRDS(file = "../../input/2_ROC_curves/RF_clinical_score_no_pt_noDAS.R",
refhook = NULL)
pred_rf_lm_profiles_p <- as.data.frame(predict(clinical_score_no_pt, clinical_scores_impute, type = "prob"))
View(pred_rf_lm_profiles_p)
View(validation_clinical)
View(pred_rf_lm_profiles_p)
validation_clinical <- read.table(
file = "../../input/2_ROC_curves/validation_clinical_score no pa or das.tsv",
header = TRUE,
row.names = 1, # Specify that the first column is row names.
sep = "\t",
stringsAsFactors = FALSE)
names(validation_clinical) <- make.names(names(validation_clinical))
validation_clinical$responses <- as.factor(c(rep("responder", 36), rep("non_responder", 8)))
validation_clinical <- rfImpute(responses ~ ., data = validation_clinical, iter = 6, ntree = 10000)
clinical_scores_impute <- sapply(validation_clinical[, -1], function(x) as.character(x))
clinical_scores_impute <- sapply(validation_clinical[, -1], function(x) as.numeric(x))
clinical_score_no_pt <- readRDS(file = "../../input/2_ROC_curves/RF_clinical_score_no_pt_noDAS.R",
refhook = NULL)
pred_rf_lm_profiles_p <- as.data.frame(predict(clinical_score_no_pt, clinical_scores_impute, type = "prob"))
rf_roc_value = roc(validation_clinical$responses, pred_rf_lm_profiles_p$non_responder)
View(validation_clinical)
View(pred_rf_lm_profiles_p)
validation_clinical <- read.table(
file = "../../input/2_ROC_curves/validation_clinical_score no pa or das.tsv",
header = TRUE,
row.names = 1, # Specify that the first column is row names.
sep = "\t",
stringsAsFactors = FALSE)
names(validation_clinical) <- make.names(names(validation_clinical))
validation_clinical$responses <- as.factor(c(rep("responder", 36), rep("non-responder", 8)))
validation_clinical <- rfImpute(responses ~ ., data = validation_clinical, iter = 6, ntree = 10000)
clinical_scores_impute <- sapply(validation_clinical[, -1], function(x) as.character(x))
clinical_scores_impute <- sapply(validation_clinical[, -1], function(x) as.numeric(x))
clinical_score_no_pt <- readRDS(file = "../../input/2_ROC_curves/RF_clinical_score_no_pt_noDAS.R",
refhook = NULL)
pred_rf_lm_profiles_p <- as.data.frame(predict(clinical_score_no_pt, clinical_scores_impute, type = "prob"))
rf_roc_value = roc(validation_clinical$responses, pred_rf_lm_profiles_p$non-responder)
rf_roc_value = roc(validation_clinical$responses, pred_rf_lm_profiles_p$`non-responder`)
pred_rf_lm_profiles <- as.data.frame(predict(model, lm_profiles_scale))
names(pred_rf_lm_profiles) <- c("prediction")
confusion_val <- confusionMatrix(factor(pred_rf_lm_profiles$prediction, levels = c("responder", "non-responder")),
factor(validation_clinical$responses, levels = c("responder", "non-responder")))
View(pred_rf_lm_profiles_p)
pred_rf_lm_profiles <- as.data.frame(predict(clinical_score_no_pt, clinical_scores_impute))
names(pred_rf_lm_profiles) <- c("prediction")
confusion_val <- confusionMatrix(factor(pred_rf_lm_profiles$prediction, levels = c("responder", "non-responder")),
factor(validation_clinical$responses, levels = c("responder", "non-responder")))
table_parameters <- as.data.frame(confusion_val$byClass)
View(table_parameters)
auc_table <- data.frame(machine_learning = models[[i]],
groups = metabolomes[[j]],
auc = round(rf_roc_value$auc, digits = 2),
sensitivity = round(table_parameters[1,1], digits = 2),
specificity = round(table_parameters[2,1], digits = 2),
TP = round(table_parameters[1,1]*100, digits = 0),
FP = 100 - round(table_parameters[2,1]*100, digits = 0),
TN = round(table_parameters[2,1]*100, digits = 0),
FN = 100 - round(table_parameters[1,1]*100, digits = 0),
stringsAsFactors = FALSE)
auc_final_table <- rbind(auc_final_table, auc_table)
View(auc_final_table)
View(auc_final_table)
auc_table <- data.frame(machine_learning = "rf",
groups = "Clin.score",
auc = round(rf_roc_value$auc, digits = 2),
sensitivity = round(table_parameters[1,1], digits = 2),
specificity = round(table_parameters[2,1], digits = 2),
TP = round(table_parameters[1,1]*100, digits = 0),
FP = 100 - round(table_parameters[2,1]*100, digits = 0),
TN = round(table_parameters[2,1]*100, digits = 0),
FN = 100 - round(table_parameters[1,1]*100, digits = 0),
stringsAsFactors = FALSE)
auc_final_table <- rbind(auc_final_table, auc_table)
View(auc_final_table)
model <- clinical_score_no_pt
View(model)
confusion <- as.data.frame(model$confusion)
View(confusion)
confusion[is.na(confusion)] <- 0
sensitivity <- confusion[2, 2]/(confusion[2, 2] + confusion[2, 1])
specificity <- confusion[1, 1]/(confusion[1, 1] + confusion[1, 2])
TP_per = (1 - confusion[2, 3])*100
FP_per = confusion[1, 3]*100
TN_per = (1 -confusion[1, 3])*100
FN_per = confusion[2, 3]*100
# Set directory to be in the source file location:
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
